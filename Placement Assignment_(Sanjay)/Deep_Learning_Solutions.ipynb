{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Dr-Sanjay/Assignment_Sanjay/blob/main/Placement%20Assignment_(Sanjay)/Deep_Learning_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGFVSuMfw_M8"
   },
   "source": [
    "#Deep_Learning_Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TiOFyQFxAxu"
   },
   "source": [
    "Question 1 -\n",
    "Implement 3 different CNN architectures with a comparison table for the MNSIT\n",
    "dataset using the Tensorflow library.\n",
    "Note -\n",
    "1. The model parameters for each architecture should not be more than 8000\n",
    "parameters\n",
    "2. Code comments should be given for proper code understanding.\n",
    "3. The minimum accuracy for each accuracy should be at least 96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIYdn1woOS1n",
    "outputId": "03d3bf2f-344b-48db-bcc4-3fb3db4b7aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5408)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                346176    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 347,146\n",
      "Trainable params: 347,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 52s 27ms/step - loss: 0.1777 - accuracy: 0.9475 - val_loss: 0.0774 - val_accuracy: 0.9752\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 0.0623 - accuracy: 0.9809 - val_loss: 0.0573 - val_accuracy: 0.9799\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 0.0420 - accuracy: 0.9868 - val_loss: 0.0458 - val_accuracy: 0.9839\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 0.0491 - val_accuracy: 0.9850\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.0509 - val_accuracy: 0.9831\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.0469 - val_accuracy: 0.9867\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.0478 - val_accuracy: 0.9863\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 40s 22ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0616 - val_accuracy: 0.9837\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0507 - val_accuracy: 0.9866\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0548 - val_accuracy: 0.9853\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0548 - accuracy: 0.9853\n",
      "Accuracy of Model 1: 0.9853000044822693\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                51264     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,714\n",
      "Trainable params: 56,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.1650 - accuracy: 0.9498 - val_loss: 0.0506 - val_accuracy: 0.9843\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0567 - accuracy: 0.9824 - val_loss: 0.0426 - val_accuracy: 0.9865\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 0.0326 - val_accuracy: 0.9895\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.0346 - val_accuracy: 0.9889\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0234 - accuracy: 0.9928 - val_loss: 0.0349 - val_accuracy: 0.9884\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.0319 - val_accuracy: 0.9895\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.0360 - val_accuracy: 0.9889\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.0419 - val_accuracy: 0.9884\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.0428 - val_accuracy: 0.9900\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.0335 - val_accuracy: 0.9909\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0335 - accuracy: 0.9909\n",
      "Accuracy of Model 2: 0.9908999800682068\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 26, 26, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               1179776   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,200,778\n",
      "Trainable params: 1,200,330\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 244s 129ms/step - loss: 0.1487 - accuracy: 0.9552 - val_loss: 0.0854 - val_accuracy: 0.9732\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 243s 130ms/step - loss: 0.0750 - accuracy: 0.9775 - val_loss: 0.0390 - val_accuracy: 0.9875\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 244s 130ms/step - loss: 0.0568 - accuracy: 0.9822 - val_loss: 0.0325 - val_accuracy: 0.9884\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 246s 131ms/step - loss: 0.0516 - accuracy: 0.9840 - val_loss: 0.0295 - val_accuracy: 0.9901\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 248s 133ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0282 - val_accuracy: 0.9912\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 247s 132ms/step - loss: 0.0343 - accuracy: 0.9890 - val_loss: 0.0328 - val_accuracy: 0.9901\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 248s 132ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 0.0288 - val_accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 248s 132ms/step - loss: 0.0282 - accuracy: 0.9907 - val_loss: 0.0282 - val_accuracy: 0.9911\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 247s 132ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.0289 - val_accuracy: 0.9910\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 247s 132ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 0.0292 - val_accuracy: 0.9915\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.0292 - accuracy: 0.9915\n",
      "Accuracy of Model 3: 0.9915000200271606\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values between 0 and 1\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Add a channels dimension (MNIST images are grayscale)\n",
    "x_train = tf.expand_dims(x_train, -1)\n",
    "x_test = tf.expand_dims(x_test, -1)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define a function to build and compile a CNN model\n",
    "def build_cnn_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Define the first CNN architecture\n",
    "model_1 = build_cnn_model()\n",
    "model_1.summary()\n",
    "\n",
    "# Train the model\n",
    "history_1 = model_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy_1 = model_1.evaluate(x_test, y_test)\n",
    "print(\"Accuracy of Model 1:\", accuracy_1)\n",
    "\n",
    "# Define the second CNN architecture\n",
    "model_2 = tf.keras.Sequential([\n",
    "    layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model_2.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_2.summary()\n",
    "\n",
    "# Train the model\n",
    "history_2 = model_2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy_2 = model_2.evaluate(x_test, y_test)\n",
    "print(\"Accuracy of Model 2:\", accuracy_2)\n",
    "\n",
    "# Define the third CNN architecture\n",
    "model_3 = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model_3.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_3.summary()\n",
    "\n",
    "# Train the model\n",
    "history_3 = model_3.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy_3 = model_3.evaluate(x_test, y_test)\n",
    "print(\"Accuracy of Model 3:\", accuracy_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJAyArUrxAzs"
   },
   "source": [
    "Question 2 -\n",
    "Implement 5 different CNN architectures with a comparison table for CIFAR 10\n",
    "dataset using the PyTorch library\n",
    "Note -\n",
    "1. The model parameters for each architecture should not be more than 10000\n",
    "parameters\n",
    "2 Code comments should be given for proper code understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUOQhOtxzau9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the transformations for data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Set batch size and number of workers for data loaders\n",
    "batch_size = 128\n",
    "num_workers = 2\n",
    "\n",
    "# Create data loaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, running_loss / len(trainloader)))\n",
    "\n",
    "# Function to test the model\n",
    "def test_model(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Architecture definition\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(128 * 5 * 5, 1024)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Model 2: LeNet-5\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # Architecture definition\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# Model 3: VGG-like Architecture\n",
    "class VGGLike(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGLike, self).__init__()\n",
    "        # Architecture definition\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512*4*4, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Model 4: ResNet-like Architecture\n",
    "class ResNetLike(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetLike, self).__init__()\n",
    "        # Architecture definition\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.residual1 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.residual2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.fc = nn.Linear(16*32*32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.residual1(x) + residual\n",
    "        residual = x\n",
    "        x = self.relu(x)\n",
    "        x = self.residual2(x) + residual\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Model 5: Custom Architecture\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # Architecture definition\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64*8*8, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create instances of the models\n",
    "simple_cnn = SimpleCNN()\n",
    "lenet5 = LeNet5()\n",
    "vgg_like = VGGLike()\n",
    "resnet_like = ResNetLike()\n",
    "custom_cnn = CustomCNN()\n",
    "\n",
    "# Print the number of parameters for each model\n",
    "print('Number of Parameters:')\n",
    "print('Simple CNN: ', sum(p.numel() for p in simple_cnn.parameters()))\n",
    "print('LeNet-5: ', sum(p.numel() for p in lenet5.parameters()))\n",
    "print('VGG-like: ', sum(p.numel() for p in vgg_like.parameters()))\n",
    "print('ResNet-like: ', sum(p.numel() for p in resnet_like.parameters()))\n",
    "print('Custom CNN: ', sum(p.numel() for p in custom_cnn.parameters()))\n",
    "\n",
    "# Train and test the models\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizers and learning rates for each model\n",
    "optimizer_simple_cnn = optim.Adam(simple_cnn.parameters(), lr=0.001)\n",
    "optimizer_lenet5 = optim.Adam(lenet5.parameters(), lr=0.001)\n",
    "optimizer_vgg_like = optim.Adam(vgg_like.parameters(), lr=0.001)\n",
    "optimizer_resnet_like = optim.Adam(resnet_like.parameters(), lr=0.001)\n",
    "optimizer_custom_cnn = optim.Adam(custom_cnn.parameters(), lr=0.001)\n",
    "\n",
    "# Train the models\n",
    "def train_model(model, criterion, optimizer):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 100 == 99:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "# Create instances of the models\n",
    "simple_cnn = SimpleCNN()\n",
    "lenet5 = LeNet5()\n",
    "vgg_like = VGGLike()\n",
    "resnet_like = ResNetLike()\n",
    "custom_cnn = CustomCNN()\n",
    "\n",
    "# Define the learning rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Define the optimizers and learning rates for each model\n",
    "optimizer_simple_cnn = optim.Adam(simple_cnn.parameters(), lr=learning_rate)\n",
    "optimizer_lenet5 = optim.Adam(lenet5.parameters(), lr=learning_rate)\n",
    "optimizer_vgg_like = optim.Adam(vgg_like.parameters(), lr=learning_rate)\n",
    "optimizer_resnet_like = optim.Adam(resnet_like.parameters(), lr=learning_rate)\n",
    "optimizer_custom_cnn = optim.Adam(custom_cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Import the necessary libraries\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the transforms to apply to the CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 training dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Create the data loader for training\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "# Train the models\n",
    "train_model(simple_cnn, criterion, optimizer_simple_cnn)\n",
    "train_model(lenet5, criterion, optimizer_lenet5)\n",
    "train_model(vgg_like, criterion, optimizer_vgg_like)\n",
    "train_model(resnet_like, criterion, optimizer_resnet_like)\n",
    "train_model(custom_cnn, criterion, optimizer_custom_cnn)\n",
    "\n",
    "# Test the models and print the accuracy\n",
    "accuracy_simple_cnn = test_model(simple_cnn)\n",
    "accuracy_lenet5 = test_model(lenet5)\n",
    "accuracy_vgg_like = test_model(vgg_like)\n",
    "accuracy_resnet_like = test_model(resnet_like)\n",
    "accuracy_custom_cnn = test_model(custom_cnn)\n",
    "\n",
    "# Print the accuracy for each model\n",
    "print('\\nAccuracy:')\n",
    "print('Simple CNN: {:.2f}%'.format(accuracy_simple_cnn))\n",
    "print('LeNet-5: {:.2f}%'.format(accuracy_lenet5))\n",
    "print('VGG-like: {:.2f}%'.format(accuracy_vgg_like))\n",
    "print('ResNet-like: {:.2f}%'.format(accuracy_resnet_like))\n",
    "print('Custom CNN: {:.2f}%'.format(accuracy_custom_cnn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCsyaGeWxA9V"
   },
   "source": [
    "Question 3 -\n",
    "Train a Pure CNN with less than 10000 trainable parameters using the MNIST\n",
    "Dataset having minimum validation accuracy of 99.40%\n",
    "Note -\n",
    "1. Code comments should be given for proper code understanding.\n",
    "2. Implement in both PyTorch and Tensorflow respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Tw1f1dozO1t"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(7 * 7 * 32, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 7 * 7 * 32)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100.0 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    validation_accuracy = 100.0 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {validation_accuracy:.2f}%\")\n",
    "    \n",
    "    # Check if the validation accuracy criterion is met\n",
    "    if validation_accuracy >= 99.40:\n",
    "        break\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'simple_cnn.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqW9EFRFxBBO"
   },
   "source": [
    "Question 4 -\n",
    "Design an end-to-end solution with diagrams for object detection use cases\n",
    "leveraging AWS cloud services and open-source tech\n",
    "Note -\n",
    "1. You need to use both AWS cloud services and open-source tech to design the\n",
    "entire solution\n",
    "2. The pipeline should consist of a data pipeline, ml pipeline, deployment pipeline,\n",
    "and inference pipeline.\n",
    "3. In the data pipeline, you would be designing how to get the data from external or\n",
    "existing sources and tech used for the same\n",
    "4. In the ml pipeline, you would be designing how to train the model, and what all\n",
    "algorithms, techniques, etc. would you be using. Again, tech used for the same 5.\n",
    "\n",
    "Since this is a deep learning project, the use of GPUs, and how effectively are you\n",
    "using them to optimize for cost and training time should also be taken into\n",
    "consideration.\n",
    "6. In the deployment pipeline, you would be designing how effectively and\n",
    "efficiently you are deploying the model in the cloud,\n",
    "7. In the inference pipeline, consider the cost of inference and its optimization\n",
    "\n",
    "related to computing resources and handling external traffic\n",
    "8. You can use any tool to design the architecture\n",
    "9. Do mention the pros and cons of your architecture and how much further it can\n",
    "be optimized and its tradeoffs.\n",
    "10. Do include a retraining approach as well.\n",
    "11. Try to include managed AWS resources for deep learning like AWS Textract,\n",
    "AWS Sagemaker, etc., and not just general-purpose compute resources like S3,\n",
    "EC2, etc. Try to mix the best of both services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWSyfhqHzOrp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWZNyZbGxBFE"
   },
   "source": [
    "Question 5 -\n",
    "\n",
    "In Question 4, you have designed the architecture for an object detection use case\n",
    "leveraging AWS Cloud, similarly, here you will be designing for Document\n",
    "Classification use case leveraging Azure Cloud services.\n",
    "Note -\n",
    "1. Most of the points are the same as in Question 4, just cloud services will\n",
    "change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCmA70XUuyqI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
