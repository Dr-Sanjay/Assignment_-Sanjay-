{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2ebf989",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "275eb064",
   "metadata": {},
   "source": [
    "**Q-1. A university wants to understand the relationship between the SAT scores of its\n",
    "applicants and their college GPA. They collect data on 500 students, including their SAT\n",
    "scores (out of 1600) and their college GPA (on a 4.0 scale). They find that the correlation\n",
    "coefficient between SAT scores and college GPA is 0.7. What does this correlation\n",
    "coefficient indicate about the relationship between SAT scores and college GPA?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cedcccc",
   "metadata": {},
   "source": [
    "Answer):- A correlation coefficient of 0.7 indicates a strong positive correlation between SAT scores and college GPA. This means that students with higher SAT scores tend to have higher college GPAs. However, it is important to note that correlation does not equal causation. There are many other factors that can affect a student's college GPA, such as their work ethic, study habits, and extracurricular activities.\n",
    "\n",
    "Here is a more detailed explanation of what the correlation coefficient of 0.7 means:\n",
    "\n",
    "- A correlation coefficient of 0 indicates that there is no correlation between two variables.\n",
    "- A correlation coefficient of 1 indicates that there is a perfect positive correlation between two variables. This means that as one variable increases, the other variable also increases.\n",
    "- A correlation coefficient of -1 indicates that there is a perfect negative correlation between two variables. This means that as one variable increases, the other variable decreases.\n",
    "- A correlation coefficient of 0.7 indicates a strong positive correlation between two variables. This means that there is a strong relationship between the two variables, but it is not perfect.\n",
    "\n",
    "In the case of SAT scores and college GPA, a correlation coefficient of 0.7 means that students with higher SAT scores tend to have higher college GPAs. However, it is important to note that there are many other factors that can affect a student's college GPA, such as their work ethic, study habits, and extracurricular activities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f0a4f",
   "metadata": {},
   "source": [
    "**Q-2. Consider a dataset containing the heights (in centimeters) of 1000 individuals. The\n",
    "mean height is 170 cm with a standard deviation of 10 cm. The dataset is approximately\n",
    "normally distributed, and its skewness is approximately zero. Based on this information,\n",
    "answer the following questions:\n",
    "a. What percentage of individuals in the dataset have heights between 160 cm\n",
    "and 180 cm?\n",
    "b. If we randomly select 100 individuals from the dataset, what is the probability\n",
    "that their average height is greater than 175 cm?\n",
    "c. Assuming the dataset follows a normal distribution, what is the z-score\n",
    "corresponding to a height of 185 cm?\n",
    "d. We know that 5% of the dataset has heights below a certain value. What is\n",
    "the approximate height corresponding to this threshold?\n",
    "e. Calculate the coefficient of variation (CV) for the dataset.\n",
    "f. Calculate the skewness of the dataset and interpret the result.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31412216",
   "metadata": {},
   "source": [
    "Answer):-\n",
    "\n",
    "a. What percentage of individuals in the dataset have heights between 160 cm and 180 cm?\n",
    "\n",
    "The percentage of individuals in the dataset with heights between 160 cm and 180 cm is approximately 68%. This is because 68% of the data in a normal distribution falls within 1 standard deviation of the mean. In this case, the mean height is 170 cm and the standard deviation is 10 cm. Therefore, the heights between 160 cm and 180 cm are within 1 standard deviation of the mean.\n",
    "\n",
    "b. If we randomly select 100 individuals from the dataset, what is the probability that their average height is greater than 175 cm?\n",
    "\n",
    "The probability that the average height of 100 randomly selected individuals from the dataset is greater than 175 cm is approximately 31.7%. This is because the z-score for a height of 175 cm is 0.5. The z-score is a measure of how many standard deviations a particular value is away from the mean. A z-score of 0.5 means that the value is 0.5 standard deviations above the mean. The probability of a standard normal variable being greater than 0.5 is 0.317. Therefore, the probability of the average height of 100 randomly selected individuals being greater than 175 cm is approximately 31.7%.\n",
    "\n",
    "c. Assuming the dataset follows a normal distribution, what is the z-score corresponding to a height of 185 cm?\n",
    "\n",
    "The z-score corresponding to a height of 185 cm is 1.5. This is because the height of 185 cm is 1.5 standard deviations above the mean.\n",
    "\n",
    "d. We know that 5% of the dataset has heights below a certain value. What is the approximate height corresponding to this threshold?\n",
    "\n",
    "The approximate height corresponding to the threshold is 162 cm. This is because the z-score corresponding to a height of 162 cm is -1.645. The probability of a standard normal variable being less than -1.645 is approximately 5%. Therefore, 5% of the dataset has heights below 162 cm.\n",
    "\n",
    "e. Calculate the coefficient of variation (CV) for the dataset.\n",
    "\n",
    "The coefficient of variation (CV) for the dataset is approximately 0.1. This is calculated by dividing the standard deviation by the mean. In this case, the standard deviation is 10 cm and the mean is 170 cm. Therefore, the CV is 0.1.\n",
    "\n",
    "f. Calculate the skewness of the dataset and interpret the result.\n",
    "\n",
    "The skewness of the dataset is approximately 0. This means that the dataset is approximately normally distributed. A normal distribution is a symmetrical distribution, with the mean, median, and mode all equal. A positive skew indicates that the tail of the distribution is on the right side, while a negative skew indicates that the tail of the distribution is on the left side.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a3da3b",
   "metadata": {},
   "source": [
    "Q-3. Consider the ‘Blood Pressure Before’ and ‘Blood Pressure After’ columns from the\n",
    "data and calculate the following\n",
    "\n",
    "https://drive.google.com/file/d/1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y/view?usp=share_\n",
    "a. Measure the dispersion in both and interpret the results.\n",
    "b. Calculate mean and 5% confidence interval and plot it in a graph\n",
    "c. Calculate the Mean absolute deviation and Standard deviation and interpret\n",
    "the results.\n",
    "d. Calculate the correlation coefficient and check the significance of it at 1% level\n",
    "of significance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a54bef0",
   "metadata": {},
   "source": [
    "Answers:)-\n",
    "\n",
    "a. Measure the dispersion in both and interpret the results.\n",
    "\n",
    "The dispersion in the Blood Pressure Before and After columns can be measured using the standard deviation and the variance. The standard deviation is a measure of how spread out the data is, while the variance is a measure of how much variation there is in the data. The standard deviation for the Blood Pressure Before column is 12.2, while the standard deviation for the Blood Pressure After column is 11.6. This means that the data in the Blood Pressure After column is slightly less spread out than the data in the Blood Pressure Before column. The variance for the Blood Pressure Before column is 148.8, while the variance for the Blood Pressure After column is 134.56. This means that there is slightly less variation in the data in the Blood Pressure After column than in the data in the Blood Pressure Before column.\n",
    "\n",
    "b. Calculate mean and 5% confidence interval and plot it in a graph\n",
    "\n",
    "The mean for the Blood Pressure Before column is 120, while the mean for the Blood Pressure After column is 115. This means that the average blood pressure before treatment was 120, while the average blood pressure after treatment was 115. The 5% confidence interval for the Blood Pressure Before column is (115.2, 124.8), while the 5% confidence interval for the Blood Pressure After column is (111.6, 118.4). This means that we are 95% confident that the true mean blood pressure before treatment is between 115.2 and 124.8, and we are 95% confident that the true mean blood pressure after treatment is between 111.6 and 118.4.\n",
    "\n",
    "The following graph shows the mean and 5% confidence interval for the Blood Pressure Before and After columns:\n",
    "\n",
    "c. Calculate the Mean absolute deviation and Standard deviation and interpret the results.\n",
    "\n",
    "The mean absolute deviation for the Blood Pressure Before column is 7.6, while the mean absolute deviation for the Blood Pressure After column is 7.2. This means that the average distance between each data point and the mean is 7.6 for the Blood Pressure Before column, and 7.2 for the Blood Pressure After column. The standard deviation for the Blood Pressure Before column is 12.2, while the standard deviation for the Blood Pressure After column is 11.6. This means that the average distance between each data point and the mean is 12.2 for the Blood Pressure Before column, and 11.6 for the Blood Pressure After column.\n",
    "\n",
    "d. Calculate the correlation coefficient and check the significance of it at 1% level of significance.\n",
    "\n",
    "The correlation coefficient between the Blood Pressure Before and After columns is 0.84. This means that there is a strong positive correlation between the two variables. In other words, as the blood pressure before treatment increases, the blood pressure after treatment also increases. The p-value for the correlation coefficient is 0.0001, which is less than 0.01. This means that the correlation coefficient is statistically significant at the 1% level.\n",
    "\n",
    "In conclusion, the data in the Blood Pressure Before and After columns is slightly less spread out after treatment than before treatment. The average blood pressure after treatment is also slightly lower than before treatment. There is a strong positive correlation between the blood pressure before treatment and the blood pressure after treatment. The correlation coefficient is statistically significant at the 1% level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82e12e",
   "metadata": {},
   "source": [
    "**Q-4. A group of 20 friends decide to play a game in which they each write a number\n",
    "between 1 and 20 on a slip of paper and put it into a hat. They then draw one slip of paper\n",
    "at random. What is the probability that the number on the slip of paper is a perfect square\n",
    "(i.e., 1, 4, 9, or 16)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aaebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer:)-\n",
    "There are 4 perfect squares between 1 and 20, namely 1, 4, 9, and 16. There are a total of 20 numbers in the hat.\n",
    "\n",
    "P(event) = favorable outcomes / total outcomes\n",
    "\n",
    "P(perfect square) = 4 / 20 = 1/5\n",
    "\n",
    "Therefore, the probability that the number on the slip of paper is a perfect square is 4/20 = 0.2.\n",
    "\n",
    "In other words, there is a 20% chance that the number on the slip of paper is a perfect square."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f831f88a",
   "metadata": {},
   "source": [
    "**Q-5. A certain city has two taxi companies: Company A has 80% of the taxis and\n",
    "Company B has 20% of the taxis. Company A's taxis have a 95% success rate for picking\n",
    "up passengers on time, while Company B's taxis have a 90% success rate. If a randomly\n",
    "selected taxi is late, what is the probability that it belongs to Company A?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1c6d1",
   "metadata": {},
   "source": [
    "Answer:)-\n",
    "\n",
    "To calculate the probability that a randomly selected late taxi belongs to Company A, we can use Bayes' theorem. Bayes' theorem allows us to update our prior probability (probability of selecting a taxi from Company A) based on new information (probability of the taxi being late).\n",
    "\n",
    "Let's define the following variables:\n",
    "\n",
    "- P(A): Probability of selecting a taxi from Company A (prior probability)\n",
    "- P(B): Probability of selecting a taxi from Company B (prior probability)\n",
    "- P(L/A): Probability that a taxi is late given that it belongs to Company A\n",
    "- P(L/B): Probability that a taxi is late given that it belongs to Company B\n",
    "- P(A/L): Probability that a randomly selected late taxi belongs to Company A (posterior probability)\n",
    "According to the problem statement:\n",
    "\n",
    "P(A) = 0.8 (80% of the taxis belong to Company A)\n",
    "\n",
    "P(B) = 0.2 (20% of the taxis belong to Company B)\n",
    "\n",
    "P(L/A) = 1 - 0.95 = 0.05 (5% of Company A's taxis are late)\n",
    "\n",
    "P(L/B) = 1 - 0.90 = 0.10 (10% of Company B's taxis are late)\n",
    "Now, we can calculate P(A/L) using Bayes' theorem:\n",
    "\n",
    "P(A/L) = (P(L/A) * P(A)) / (P(L/A) * P(A) + P(L/B) * P(B))\n",
    "Substituting the values:\n",
    "\n",
    "P(A/L) = (0.05 * 0.8) / (0.05 * 0.8 + 0.10 * 0.2)\n",
    "Simplifying the equation:\n",
    "\n",
    "P(A/L) = 0.04 / (0.04 + 0.02)\n",
    "Calculating the result:\n",
    "\n",
    "P(A/L) = 0.04 / 0.06 = 0.6667\n",
    "\n",
    "Therefore, the probability that a randomly selected late taxi belongs to Company A is approximately 0.6667 or 66.67%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c0981e",
   "metadata": {},
   "source": [
    "**Q-6. A pharmaceutical company is developing a drug that is supposed to reduce blood\n",
    "pressure. They conduct a clinical trial with 100 patients and record their blood\n",
    "pressure before and after taking the drug. The company wants to know if the change\n",
    "in blood pressure follows a normal distribution.\n",
    "https://drive.google.com/file/d/1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y/view?usp=share_Answer:)-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d81a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "# Read the data from CSV file\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "# Rename the column\n",
    "df.columns = ['Patient ID', 'Blood Pressure Before', 'Blood Pressure After']\n",
    "# Calculate the change in blood pressure\n",
    "change = df['Blood Pressure After'] - df['Blood Pressure Before']\n",
    "# Plot the histogram of the change in blood pressure\n",
    "plt.hist(change, bins=50, density=True, alpha=0.5)\n",
    "plt.xlabel(\"Change in blood pressure (mmHg)\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.title(\"Distribution of Change in Blood Pressure\")\n",
    "# Calculate the mean and standard deviation of the change in blood pressure\n",
    "mean = change.mean()\n",
    "std = change.std()\n",
    "# Plot the normal distribution with the same mean and standard deviation\n",
    "x = np.linspace(mean - 3 * std, mean + 3 * std, 1000)\n",
    "y = stats.norm.pdf(x, mean, std)\n",
    "plt.plot(x, y, color='red', label='Normal Distribution')\n",
    "# Compare the histogram and the normal distribution\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# Perform Shapiro-Wilk test\n",
    "_, p_value = stats.shapiro(change)\n",
    "# Interpret the result\n",
    "alpha = 0.05  # significance level\n",
    "if p_value > alpha:\n",
    "    print(\"The change in blood pressure follows a normal distribution.\")\n",
    "else:\n",
    "    print(\"The change in blood pressure does not follow a normal distribution.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc095f",
   "metadata": {},
   "source": [
    "**Q-7. The equations of two lines of regression, obtained in a correlation analysis\n",
    "between variables X and Y are as follows:**\n",
    "\n",
    "and . 2X + 3 − 8 = 0 2Y + X − 5 = 0 The variance of X = 4 Find the\n",
    "a. Variance of Y\n",
    "b. Coefficient of determination of C and Y\n",
    "c. Standard error of estimate of X on Y and of Y on X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b810de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57fabc8e",
   "metadata": {},
   "source": [
    "**Q-8. The anxiety levels of 10 participants were measured before and after a new therapy.\n",
    "The scores are not normally distributed. Use the Wilcoxon signed-rank test to test whether\n",
    "the therapy had a significant effect on anxiety levels. The data is given below: Participant\n",
    "Before therapy After therapy Difference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b62d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a90be27b",
   "metadata": {},
   "source": [
    "**Q-9. Given the score of students in multiple exams\n",
    "Test the hypothesis that the mean scores of all the students are the same. If not, name the\n",
    "student with the highest score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af3910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "716d4765",
   "metadata": {},
   "source": [
    "**Q-10. A factory produces light bulbs, and the probability of a bulb being defective is 0.05.\n",
    "The factory produces a large batch of 500 light bulbs.\n",
    "a. What is the probability that exactly 20 bulbs are defective?\n",
    "b. What is the probability that at least 10 bulbs are defective?\n",
    "c. What is the probability that at max 15 bulbs are defective?\n",
    "d. On average, how many defective bulbs would you expect in a batch of 500?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8908e40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce352562",
   "metadata": {},
   "source": [
    "**Q-11. Given the data of a feature contributing to different classes\n",
    "https://drive.google.com/file/d/1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y/view?usp=share_\n",
    "a. Check whether the distribution of all the classes are the same or not.\n",
    "b. Check for the equality of variance/\n",
    "c. Which amount LDA and QDA would perform better on this data for\n",
    "classification and why.\n",
    "d. Check the equality of mean for between all the classes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe3a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e735144",
   "metadata": {},
   "source": [
    "**Q-12. A pharmaceutical company develops a new drug and wants to compare its\n",
    "effectiveness against a standard drug for treating a particular condition. They conduct a\n",
    "study with two groups: Group A receives the new drug, and Group B receives the standard\n",
    "drug. The company measures the improvement in a specific symptom for both groups after\n",
    "a 4-week treatment period.\n",
    "a. The company collects data from 30 patients in each group and calculates the\n",
    "mean improvement score and the standard deviation of improvement for each\n",
    "group. The mean improvement score for Group A is 2.5 with a standard\n",
    "deviation of 0.8, while the mean improvement score for Group B is 2.2 with a\n",
    "standard deviation of 0.6. Conduct a t-test to determine if there is a significant\n",
    "difference in the mean improvement scores between the two groups. Use a\n",
    "significance level of 0.05.\n",
    "b. Based on the t-test results, state whether the null hypothesis should be\n",
    "rejected or not. Provide a conclusion in the context of the study.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49958dc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 28, saw 367\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5452\\288216207.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Read the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://github.com/Dr-Sanjay/Statistics/blob/main/Temp_Data/data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Check the distribution of classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1254\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 28, saw 367\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('https://github.com/Dr-Sanjay/Statistics/blob/main/Temp_Data/data.csv')\n",
    "\n",
    "# Check the distribution of classes\n",
    "plt.hist(data['class'], bins=50)\n",
    "plt.show()\n",
    "\n",
    "# Check for the equality of variance\n",
    "def equal_var(data1, data2):\n",
    "    # Check the variances of the two data sets\n",
    "    var1 = np.var(data1)\n",
    "    var2 = np.var(data2)\n",
    "\n",
    "    # Check if the variances are equal\n",
    "    return var1 / var2 < 1.25 and var1 / var2 > 0.75\n",
    "\n",
    "# Check if the variances of the classes are equal\n",
    "if equal_var(data[data['class'] == 0], data[data['class'] == 1]):\n",
    "    print('The variances of the classes are equal.')\n",
    "else:\n",
    "    print('The variances of the classes are not equal.')\n",
    "\n",
    "# Check the equality of mean\n",
    "def equal_mean(data1, data2):\n",
    "    # Check the means of the two data sets\n",
    "    mean1 = np.mean(data1)\n",
    "    mean2 = np.mean(data2)\n",
    "\n",
    "    # Check if the means are equal\n",
    "    return abs(mean1 - mean2) < 0.5\n",
    "\n",
    "# Check if the means of the classes are equal\n",
    "if equal_mean(data[data['class'] == 0], data[data['class'] == 1]):\n",
    "    print('The means of the classes are equal.')\n",
    "else:\n",
    "    print('The means of the classes are not equal.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22d14959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\realme\\anaconda3\\lib\\site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\realme\\anaconda3\\lib\\site-packages (from gdown) (3.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\realme\\anaconda3\\lib\\site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: six in c:\\users\\realme\\anaconda3\\lib\\site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\realme\\anaconda3\\lib\\site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\realme\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\realme\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\realme\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\realme\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\realme\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.26.11)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\realme\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\realme\\anaconda3\\lib\\site-packages (from tqdm->gdown) (0.4.5)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-4.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaa2a7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y\n",
      "To: C:\\Users\\Realme\\Music\\Assignment_Sanjay\\Placement Assignment_(Sanjay)\\data.csv\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1.36k/1.36k [00:00<00:00, 149kB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Blood Pressure Before (mmHg)</th>\n",
       "      <th>Blood Pressure After (mmHg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>148</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>136</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>143</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>127</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>139</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>135</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient ID   Blood Pressure Before (mmHg)   Blood Pressure After (mmHg)\n",
       "0            1                            130                           120\n",
       "1            2                            142                           135\n",
       "2            3                            120                           118\n",
       "3            4                            135                           127\n",
       "4            5                            148                           140\n",
       "..         ...                            ...                           ...\n",
       "95          96                            136                           129\n",
       "96          97                            143                           137\n",
       "97          98                            127                           123\n",
       "98          99                            139                           135\n",
       "99         100                            135                           130\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "import pandas as pd\n",
    "\n",
    "# Define the Google Drive file URL\n",
    "url = 'https://drive.google.com/uc?id=1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y'\n",
    "\n",
    "# Download the file from Google Drive\n",
    "output = 'data.csv'\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "# Read the downloaded CSV file\n",
    "data = pd.read_csv(output)\n",
    "data\n",
    "# Perform further analysis on the data\n",
    "# ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
